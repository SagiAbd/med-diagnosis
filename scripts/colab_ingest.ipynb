{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med-Diagnosis: Embedding Ingestion\n",
    "\n",
    "**Input:** pre-chunked documents in LangChain format (JSON)  \n",
    "```json\n",
    "[\n",
    "  {\"page_content\": \"...\", \"metadata\": {\"source\": \"file.pdf\", ...}},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Outputs:**\n",
    "- `corpus.json` → copy to `./backend/data/corpus.json`\n",
    "- `chroma_export.zip` → extract as `./chroma_data/` in project root\n",
    "\n",
    "On next app startup, `corpus_loader.py` reads `corpus.json` for SQL records  \n",
    "and skips Chroma embedding (vectors already present)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q chromadb>=0.6.3 langchain-chroma>=0.0.5 langchain-huggingface langchain-openai sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CONFIG ────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Path to your pre-chunked JSON file (LangChain format)\n",
    "INPUT_JSON = \"/content/chunks.json\"\n",
    "\n",
    "# Outputs\n",
    "CHROMA_PATH = \"/content/chroma_data\"   # → ./chroma_data/ in project\n",
    "CORPUS_JSON = \"/content/corpus.json\"   # → ./backend/data/corpus.json\n",
    "\n",
    "# Must match CHROMA_COLLECTION_NAME in .env (default: \"documents\")\n",
    "COLLECTION_NAME = \"documents\"\n",
    "\n",
    "# ── Embeddings ──\n",
    "# \"huggingface\" : local GPU inference (must use the SAME model as TEI)\n",
    "# \"openai\"      : OpenAI-compatible API\n",
    "EMBEDDINGS_MODE  = \"huggingface\"\n",
    "EMBEDDINGS_MODEL = \"google/embeddinggemma-300m\"  # must match TEI MODEL_ID\n",
    "HF_TOKEN         = \"your-hf-token-here\"\n",
    "\n",
    "# OpenAI (only if EMBEDDINGS_MODE=\"openai\")\n",
    "OPENAI_API_KEY   = \"\"\n",
    "OPENAI_API_BASE  = \"https://api.openai.com/v1\"\n",
    "OPENAI_EMB_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Imports ───────────────────────────────────────────────────────────────\n",
    "import hashlib, json, os, shutil\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document as LangchainDocument\n",
    "\n",
    "os.makedirs(CHROMA_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ── Load pre-chunked data (supports .json and .jsonl) ────────────────────\next = os.path.splitext(INPUT_JSON)[1].lower()\nwith open(INPUT_JSON, encoding=\"utf-8\") as f:\n    if ext == \".jsonl\":\n        raw: list[dict] = [json.loads(line) for line in f if line.strip()]\n    else:\n        raw: list[dict] = json.load(f)\n\nprint(f\"Loaded {len(raw)} chunks from {INPUT_JSON}\")\nprint(\"Sample:\", raw[0][\"page_content\"][:120], \"...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Assign chunk IDs (must match corpus_loader.py formula) ───────────────\n",
    "# chunk_id = SHA256(f\"{source_file_name}:{page_content}\")\n",
    "for chunk in raw:\n",
    "    page_content = chunk[\"page_content\"]\n",
    "    file_name    = chunk.get(\"metadata\", {}).get(\"source\", \"corpus\")\n",
    "    chunk[\"_id\"] = hashlib.sha256(f\"{file_name}:{page_content}\".encode()).hexdigest()\n",
    "\n",
    "print(\"Chunk IDs assigned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Embeddings model ──────────────────────────────────────────────────────\n",
    "if EMBEDDINGS_MODE == \"huggingface\":\n",
    "    import torch\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Device: {device}\")\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=EMBEDDINGS_MODEL,\n",
    "        model_kwargs={\"device\": device, \"token\": HF_TOKEN},\n",
    "        encode_kwargs={\"normalize_embeddings\": True},\n",
    "    )\n",
    "elif EMBEDDINGS_MODE == \"openai\":\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE, model=OPENAI_EMB_MODEL,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown EMBEDDINGS_MODE: {EMBEDDINGS_MODE}\")\n",
    "\n",
    "print(f\"Embedding dim: {len(embeddings.embed_query('test'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Chroma setup ──────────────────────────────────────────────────────────\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "vector_store  = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "existing_ids = set(vector_store._collection.get()[\"ids\"])\n",
    "print(f\"Collection '{COLLECTION_NAME}': {len(existing_ids)} existing vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Embed & store (skips already-present chunks) ──────────────────────────\n",
    "to_embed = [\n",
    "    LangchainDocument(\n",
    "        page_content=c[\"page_content\"],\n",
    "        metadata=c.get(\"metadata\", {}),\n",
    "        id=c[\"_id\"],\n",
    "    )\n",
    "    for c in raw if c[\"_id\"] not in existing_ids\n",
    "]\n",
    "print(f\"{len(to_embed)} new chunks to embed  ({len(raw) - len(to_embed)} already present)\")\n",
    "\n",
    "BATCH = 100\n",
    "for i in range(0, len(to_embed), BATCH):\n",
    "    batch = to_embed[i:i+BATCH]\n",
    "    vector_store.add_documents(batch, ids=[d.id for d in batch])\n",
    "    print(f\"  {min(i+BATCH, len(to_embed))}/{len(to_embed)}\")\n",
    "\n",
    "print(f\"Done. Collection total: {vector_store._collection.count()} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Save corpus.json (strip internal _id key) ─────────────────────────────\n",
    "corpus = [{\"page_content\": c[\"page_content\"], \"metadata\": c.get(\"metadata\", {})} for c in raw]\n",
    "with open(CORPUS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(corpus, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Saved {len(corpus)} chunks → {CORPUS_JSON}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Package & download ────────────────────────────────────────────────────\n",
    "shutil.make_archive(\"/content/chroma_export\", \"zip\", \"/content\", \"chroma_data\")\n",
    "print(\"Zipped → /content/chroma_export.zip\")\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(CORPUS_JSON)\n",
    "    files.download(\"/content/chroma_export.zip\")\n",
    "except ImportError:\n",
    "    print(f\"Files ready:\\n  {CORPUS_JSON}\\n  /content/chroma_export.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "```bash\n",
    "cp corpus.json ./backend/data/corpus.json\n",
    "unzip -o chroma_export.zip -d .\n",
    "docker compose -f docker-compose.dev.cpu.yml up -d --build\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}